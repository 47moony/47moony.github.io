{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"GAMES101","slug":"GAMES101","date":"2022-11-01T13:13:51.000Z","updated":"2022-11-01T13:35:29.711Z","comments":true,"path":"2022/11/01/GAMES101/","link":"","permalink":"http://example.com/2022/11/01/GAMES101/","excerpt":"","text":"GAMES101Studies for GAMES101. 2022&#x2F;04&#x2F;12完成了作业二以及MSAA。目前没有学习z-buffer的插值函数，所以直接用了框架提供的代码。 目前效果是：如下图所示，三角形周围有黑线。 对应代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748void rst::rasterizer::updateColorAndDepth(int x, int y, const Triangle&amp; t, float color_percent = 1.0f)&#123; // 转换为齐次坐标 // 在这一步，已经经过了MVP变换为了屏幕上的点，所以只需要知道x, y的信息即可 auto v = t.toVector4(); // If so, use the following code to get the interpolated z value. // 这是插值函数，目前还没学到（刚上完p7）；这里加0.5f没有出错 // auto[alpha, beta, gamma] = computeBarycentric2D(x + 0.5f, y + 0.5f, t.v); auto[alpha, beta, gamma] = computeBarycentric2D(x, y, t.v); float w_reciprocal = 1.0/(alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w()); float z_interpolated = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w(); z_interpolated *= w_reciprocal; // 还是z的问题，因为z是负值，所以如果越近，z越大 // 因此depth_buf初始化的时候应该是用-inf来初始化才对 if(z_interpolated &gt; depth_buf[get_index(x, y)]) &#123; // TODO : set the current pixel (use the set_pixel function) to the color of the triangle (use getColor function) if it should be painted. // 用像素的中心来判断 但是加了0.5会导致缺一块 // 猜测加了0.5f出错是因为x, y应该是像素的index而不是像素中心的坐标点 Eigen::Vector3f point = Eigen::Vector3f(x, y, 1.0f); set_pixel(point, t.getColor() * color_percent); // 更新depth_buf depth_buf[get_index(x, y)] = z_interpolated; &#125;&#125;if(MSAA)&#123; // 定义super-sampling的形状 int m = 2; int n = 2; float total_samples = static_cast&lt;float&gt;(m * n); int count = 0; for(int i = 0; i &lt; m; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; Eigen::Vector2f p(x+(0.5f+i)/m, y+(0.5f+j)/n); if(insideTrianglePoint(p, t.v)) count++; &#125; &#125; float color_percent = static_cast&lt;float&gt;(count) / total_samples; if(color_percent &gt; 0) &#123; updateColorAndDepth(x, y, t, color_percent); &#125;&#125; 2022&#x2F;04&#x2F;19去掉了黑线 1234567891011121314151617181920212223242526272829void rst::rasterizer::updateColorAndDepth(int x, int y, const Triangle&amp; t, float color_percent = 1.0f)&#123; int ind = get_index(x, y); // 转换为齐次坐标 // 在这一步，已经经过了MVP变换为了屏幕上的点，所以只需要知道x, y的信息即可 auto v = t.toVector4(); // If so, use the following code to get the interpolated z value. // 这是插值函数，目前还没学到（刚上完p7）；这里加0.5f没有出错 // auto[alpha, beta, gamma] = computeBarycentric2D(x + 0.5f, y + 0.5f, t.v); auto[alpha, beta, gamma] = computeBarycentric2D(x, y, t.v); float w_reciprocal = 1.0/(alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w()); float z_interpolated = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w(); z_interpolated *= w_reciprocal; // 还是z的问题，因为z是负值，所以如果越近，z越大 // 因此depth_buf初始化的时候应该是用-inf来初始化才对 if(z_interpolated &gt; depth_buf[ind]) &#123; // TODO : set the current pixel (use the set_pixel function) to the color of the triangle (use getColor function) if it should be painted. // 用像素的中心来判断 但是加了0.5会导致缺一块 // 猜测加了0.5f出错是因为x, y应该是像素的index而不是像素中心的坐标点 Eigen::Vector3f point = Eigen::Vector3f(x, y, 1.0f); set_pixel(point, t.getColor() * color_percent + frame_buf[ind] * (1 - color_percent)); // 更新depth_buf depth_buf[ind] = z_interpolated; &#125; // 为了将边界处的深度初始化，因为如果存在重叠的情况，需要更新下方的颜色，否则比较大小内不会执行（颜色不更新） if(color_percent &lt; 1.0f) depth_buf[ind] = - std::numeric_limits&lt;float&gt;::infinity();&#125; 具体来说，首先着色的是绿色的三角形，如果是边界，那么color_percent一定小于1，这时，由于是第一次着色，所以原本的frame_buffer中存的是黑色(0, 0, 0)，如果有颜色的占比很小，那么MSAA混合出来的颜色就会很深，看着就像一条黑线。所以需要将depth_buffer初始化，在而后对处于下方的蓝色三角形进行着色时，这个原本的黑色边界就会被着色为蓝色，边界也就不存在了。 Hw01向量绕任意轴旋转的简单推导 | Sulley图形学中有关旋转的一个问题是，一个（三维空间的）向量绕一个任意轴旋转若干角度后的角度是什么。本文简单进行推导，给出显式结果。 方法一：向量分解推导过程首先介绍一个最容易理解的方法——向量分解。假设要旋转的向量是p，要旋转的轴是n，是一个单位向量，要旋转的角度是θ。再设旋转后的轴是p′。 现在我们把p分解为两个向量，一个平行于n，另一个垂直于n，即：p&#x3D;p⊥+p∥容易知道，平行于n的分向量p∥就是p在n上的投影（推导过程略）：p∥&#x3D;(n⋅p)n从而就能得到p⊥：p⊥&#x3D;p−p∥同样地可以将旋转后的向量分解：p′&#x3D;p⊥′+p∥′显然，旋转后的向量对应的平行分量p∥′是不变的：p∥′&#x3D;p∥这里的关键在于求垂直分量p⊥′。 将向量分解为一个平行向量和一个垂直向量 根据已知的旋转轴n，我们就知道它对应的平面V，而向量p与p′的垂直分量就在该平面内。该平面的维度是2，因此只需要找到两个基向量，就可以通过这两个基向量的线性组合表示该平面的任意向量。 其中一个基向量我们已经找到了，就是p⊥，而另一个我们可以通过n与p⊥的叉乘实现，得到的向量与n和p⊥垂直，且在平面V内。且注意到：n×p⊥&#x3D;n×(p−p∥)&#x3D;n×p−n×p∥&#x3D;n×p并且有：‖n×p‖&#x3D;‖n×p⊥‖&#x3D;‖n‖⋅‖p⊥‖⋅sin⁡(π&#x2F;2)&#x3D;‖p⊥‖进而我们能导出旋转后的垂直分量p⊥′：p⊥′&#x3D;cos⁡(θ)‖p⊥‖⋅p⊥‖p⊥‖+sin⁡(θ)‖p⊥‖⋅n×p‖n×p‖&#x3D;cos⁡(θ)p⊥+sin⁡(θ)(n×p)最后，我们得到旋转后的向量p′： p′&#x3D;p⊥′+p∥′&#x3D;cos⁡(θ)p⊥+sin⁡(θ)(n×p)+p∥&#x3D;cos⁡(θ)(p−p∥)+p∥+sin⁡(θ)(n×p)&#x3D;cos⁡(θ)p+(1−cos⁡(θ))(n⋅p)n+sin⁡(θ)(n×p) 搞定！ 矩阵形式我们知道向量的叉乘可以表示为：n×p&#x3D;[0−nznynz0−nx−nynx0]p&#x3D;Np注意到，矩阵N有如下的性质：N(Np)&#x3D;N2p&#x3D;n×(n×p)所以我们可以把旋转公式写成下述形式：p′&#x3D;p+(1−cos⁡(θ))N2p+sin⁡(θ)Np&#x3D;Rp其中R&#x3D;I+sin⁡(θ)N+(1−cos⁡(θ))N2。上面的等式需要注意到(n⋅p)n&#x3D;p+N2p。 所以，使用Rodrigues’旋转公式，只需要首先令N&#x3D;[0−nznynz0−nx−nynx0]，然后再计算R&#x3D;I+sin⁡(θ)N+(1−cos⁡(θ))N2，就能得到旋转后的向量为p′&#x3D;Rp。 方法二：坐标轴对齐既然直接绕着任意轴旋转比较困难，那为啥不先进行整个空间的旋转，把旋转轴旋转为坐标轴，这样就能把向量绕任意轴旋转转化为向量绕标准坐标轴旋转。这就是我们非常熟悉的问题了。 假定我们考虑的是三维空间的旋转（对更高维的情况容易推论），即标准坐标系为x&#x3D;(1,0,0),y&#x3D;(0,1,0),z&#x3D;(0,0,1)。我们有旋转轴n,‖n‖&#x3D;1和待旋转向量p。 首先，我们构建一个坐标系u,v,w，该坐标系的一个轴就是n，我们利用叉乘实现： u&#x3D;n,v&#x3D;n×p‖n×p‖,w&#x3D;n×v 现在，我们要把坐标轴u,v,w分别旋转到坐标轴x,y,z的位置，这可以用下面的旋转矩阵实现： Q&#x3D;[uvw]&#x3D;[xuyuzuxvyvzvxwywzw] 很容易验证：x&#x3D;Qu,y&#x3D;Qv,z&#x3D;Qw，从而就有I&#x3D;QQ⊤&#x3D;Q⊤Q，这就验证了Q是正交的。 现在，原来的向量p就变成了Qp，原来绕n旋转（也就是绕u旋转）就变成了绕x旋转，而我们知道绕x轴旋转θ的旋转矩阵是：T&#x3D;[1000cos⁡(θ)−sin⁡(θ)0sin⁡(θ)cos⁡(θ)]因此，旋转后的向量就是TQp。现在，只需要把旋转后的向量再旋转回原来的位置就好了，我们只需要再乘以Q的逆即可。由于Q是正交的，所以有Q−1&#x3D;Q⊤。把上面的结果合起来，就能得到最终的结果是：p′&#x3D;Q⊤TQp 检验现在我们用代码来检验一下上述三种方法是否能得到同样的结果，以及它们的运算效率如何。比较的方法包括： 1. 向量分解-向量形式 2. 向量分解-矩阵形式 3. 对标轴对齐 程序在虚拟机上运行，RAM为4G，硬盘20G，处理器为2个Intel Core i5-10400F CPU @ 2.90GHz。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include&lt;iostream&gt;#include&lt;eigen3/Eigen/Eigen&gt;#include&lt;string&gt;#include&lt;opencv2/opencv.hpp&gt;#include&lt;chrono&gt;using namespace std;const double PI = 3.1415926;// rotation using vector decomposation - the vector formvoid DecomposeVector(const Eigen::Vector3f &amp;n, const Eigen::Vector3f &amp;p, float angle) &#123;double rotationAngle = angle / 180.0 * PI;auto startTime = std::chrono::high_resolution_clock::now();Eigen::Vector3f rotatedVector = cos(rotationAngle) * p + (1 - cos(rotationAngle)) * (n.dot(p)) * n + sin(rotationAngle) * (n.cross(p));auto endTime = std::chrono::high_resolution_clock::now();double deltaTime = std::chrono::duration&lt;double, std::milli&gt;(endTime-startTime).count();cout &lt;&lt; &quot;Method: vector decomposition - the vector form. The rotated vector p&#x27; is (&quot; &lt;&lt; rotatedVector(0) &lt;&lt; &quot;,&quot; &lt;&lt; rotatedVector(1) &lt;&lt; &quot;,&quot; &lt;&lt; rotatedVector(2) &lt;&lt; &quot;). The time used is &quot; &lt;&lt; deltaTime &lt;&lt; endl;&#125;// rotation using vector decomposation - the matrix formvoid DecomposeMatrix(const Eigen::Vector3f &amp;n, const Eigen::Vector3f &amp;p, float angle) &#123;double rotationAngle = angle / 180.0 * PI;auto startTime = std::chrono::high_resolution_clock::now();Eigen::Matrix3f N = Eigen::Matrix3f::Identity();N &lt;&lt; 0, -n(2), n(1), n(2), 0, -n(0), -n(1), n(0), 0;Eigen::Matrix3f R = Eigen::Matrix3f::Identity() + sin(rotationAngle) * N + (1 - cos(rotationAngle)) * N * N;Eigen::Vector3f rotatedVector = R * p;auto endTime = std::chrono::high_resolution_clock::now();double deltaTime = std::chrono::duration&lt;double, std::milli&gt;(endTime-startTime).count();cout &lt;&lt; &quot;Method: vector decomposition - the matrix form. The rotated vector p&#x27; is (&quot; &lt;&lt; rotatedVector(0) &lt;&lt; &quot;,&quot; &lt;&lt; rotatedVector(1) &lt;&lt; &quot;,&quot; &lt;&lt; rotatedVector(2) &lt;&lt; &quot;). The time used is &quot; &lt;&lt; deltaTime &lt;&lt; endl;&#125;// rotation using axis coordinationvoid AxisCoordination(const Eigen::Vector3f &amp;n, const Eigen::Vector3f &amp;p, float angle) &#123;double rotationAngle = angle / 180.0 * PI;auto startTime = std::chrono::high_resolution_clock::now();Eigen::Vector3f crossed = n.cross(p);Eigen::Vector3f u = n;Eigen::Vector3f v = crossed / crossed.norm();Eigen::Vector3f w = n.cross(v);Eigen::Matrix3f Q = Eigen::Matrix3f::Identity(), T = Eigen::Matrix3f::Identity();Q.row(0) = u;Q.row(1) = v;Q.row(2) = w;T &lt;&lt; 1, 0, 0, 0, cos(rotationAngle), -sin(rotationAngle), 0, sin(rotationAngle), cos(rotationAngle);Eigen::Vector3f rotatedVector = Q.transpose() * T * Q * p;auto endTime = std::chrono::high_resolution_clock::now();double deltaTime = std::chrono::duration&lt;double, std::milli&gt;(endTime-startTime).count();cout &lt;&lt; &quot;Method: axis coordination. The rotated vector p&#x27; is (&quot; &lt;&lt; rotatedVector(0) &lt;&lt; &quot;,&quot; &lt;&lt; rotatedVector(1) &lt;&lt; &quot;,&quot; &lt;&lt; rotatedVector(2) &lt;&lt; &quot;). The time used is &quot; &lt;&lt; deltaTime &lt;&lt; endl;&#125;// mainint main()&#123; float angle = 60; Eigen::Vector3f p(1.0, 2.0, 3.0); Eigen::Vector3f n(2.0, 8.6, -3.1); n.normalize(); // execute functions cout &lt;&lt; &quot;The vector p is (&quot; &lt;&lt; p(0) &lt;&lt; &quot;,&quot; &lt;&lt; p(1) &lt;&lt; &quot;,&quot; &lt;&lt; p(2) &lt;&lt; &quot;). &quot; &lt;&lt; &quot;The rotation axis n is (&quot; &lt;&lt; n(0) &lt;&lt; &quot;,&quot; &lt;&lt; n(1) &lt;&lt; &quot;,&quot; &lt;&lt; n(2) &lt;&lt; &quot;). &quot; &lt;&lt; endl; DecomposeVector(n, p, angle); DecomposeMatrix(n, p, angle); AxisCoordination(n, p, angle); return 0;&#125; 输出是： 1234The vector p is (1,2,3). The rotation axis n is (0.213724,0.919011,-0.331271). Method: vector decomposition - the vector form. The rotated vector p&#x27; is (3.57449,0.643966,0.899062). The time used is 0.016354Method: vector decomposition - the matrix form. The rotated vector p&#x27; is (3.57449,0.643966,0.899062). The time used is 0.016642Method: axis coordination. The rotated vector p&#x27; is (3.57449,0.643966,0.899062). The time used is 0.021062 再多试几组： 1234The vector p is (1,-654.1,12.88). The rotation axis n is (0.995044,0.0136933,-0.0984901). Method: vector decomposition - the vector form. The rotated vector p&#x27; is (-59.7309,-338.298,-556.777). The time used is 0.015503Method: vector decomposition - the matrix form. The rotated vector p&#x27; is (-59.7309,-338.298,-556.777). The time used is 0.015297Method: axis coordination. The rotated vector p&#x27; is (-59.7309,-338.298,-556.777). The time used is 0.021547 12345678The vector p is (32.5,45.1,-2.2). The rotation axis n is (0.57735,0.57735,0.57735). Method: vector decomposition - the vector form. The rotated vector p&#x27; is (5.16667,52.4667,17.7667). The time used is 0.015558Method: vector decomposition - the matrix form. The rotated vector p&#x27; is (5.16667,52.4667,17.7667). The time used is 0.015215Method: axis coordination. The rotated vector p&#x27; is (5.16667,52.4667,17.7667). The time used is 0.020841The vector p is (666,0,0). The rotation axis n is (0,0,1). Method: vector decomposition - the vector form. The rotated vector p&#x27; is (1.78454e-05,666,0). The time used is 0.01517Method: vector decomposition - the matrix form. The rotated vector p&#x27; is (0,666,0). The time used is 0.015402Method: axis coordination. The rotated vector p&#x27; is (1.78454e-05,666,0). The time used is 0.020898 最后一组出现了精度问题，所以代码中还应该加入判断 12if(abs(value - round(value)) &lt; epsilon) value = round(value); 从上面的例子来看，向量分解-向量形式与向量分解-矩阵形式运行效率是一致的，而坐标轴对齐的效率较低，这主要是由计算三次矩阵乘法导致的。 上面这个推导公式有问题，参考了下面的公式，更通用。 【GAMES101】作业1（提高）与框架理解 (betheme.net) tips1， Eigen中的矩阵和向量运算不会自动适应行列数，需要在编程的时候保证参与运算的矩阵和向量行列数可以进行运算2，头文件&lt;Eigen&#x2F;Core&gt; 中包含【+，-，，&#x2F;，+&#x3D;，-&#x3D;，&#x3D;，.transpose()…sum()，.prod()，.mean()，minCoeff()，.maxCoeff，.trace()】等运算符3，头文件&lt;Eigen&#x2F;Dense&gt; 中包含【.dot()，.cross()，adjoint()】等运算符4，以下讨论的符号约定(假设满足运算的行列数要求)矩阵：a，b向量：u，v常数：c 1，【+，+&#x3D;，-，-&#x3D;】适用于尺寸相同的矩阵之间、尺寸相同的向量之间的对应元素相加减 2，【，&#x3D;】1，用于矩阵与矩阵：尺寸合适的矩阵的一般矩阵乘法。此时，向量可以看成是矩阵2，用于矩阵与标量：矩阵与标量的一般乘法，矩阵每个元素与标量相乘。此时，向量可以看成是矩阵 3，【.transpose()】返回矩阵的转置。此时，向量可以看成是矩阵 4，【.dot()，.cross()，.adjoint()】只用于向量 12345u.dot(v):u和v的点乘，即对应元素乘积的和，返回一个标量。与v.dot(u)，u.transpose()*v，v.transpose()*u相同。u.cross(v):u和v的叉积，返回一个向量。与v.cross(u)相差一个负号。u.adjoint():返回u的共轭向量，若u为实向量，则返回结果与u相同。 5，针对矩阵元素进行的操作【.sum()，.prod()，.mean()，minCoeff()，.maxCoeff，.trace()】本部分所有操作都可对矩阵和向量进行，将向量看做矩阵即可 1234567891011a.sum()： 返回矩阵a中所有元素的和a.prod()： 返回矩阵a中所有元素的积a.mean()： 返回矩阵a中所有有元素的平均值a.trace(): 返回矩阵的迹，即返回主对角线上元素的和。如果不是方阵或者为向量，仍返回对角线元素的和。a.minCoeff()： 返回矩阵中最小的元素a.maxCoeff()： 返回矩阵中最大的元素另外，对于.minCoeff()，.maxCoeff()，有以下用法：int i,j;//或std::ptrdiff_t i, jauto min = a.minCoeff(i,j);返回a的最小元素赋值给min，并将最小元素所在行号、列号赋值给i、j。auto max = a.maxCoeff(p,q);返回a的最大元素赋值给max，并将最大元素所在行号、列号赋值给q、p。 6，【.norm()】向量求模，矩阵范数12a.norm();//返回矩阵的Frobenius范数，即元素平方的和的平方根u.norm();//返回向量的模 Hw02产生黑边的原因主要为：这时采用的为原图片大小的深度缓存空间，两个三角形位置为关系为绿色在上（前），蓝色在下（后）面，绘制时的顺序也按照这样。在计算完绿色三角形之后，帧缓存和深度缓存均已更新，三角形边缘的地方像素颜色采用覆盖比率插值计算，深度值为绿色三角形在该坐标所计算出的深度插值。根据上面的话，这条黑色的边其实并不是真的的黑色，而是插值之后的绿色，只不过是由于覆盖比率很小在插值之后rgb值变得很低，颜色的饱和度与亮度会随之下降。例如原rgb值为（200,200,100），若覆盖比率为4&#x2F;16的话，如下面效果，若覆盖率更低那么会更接近黑色。（参考：https://blog.csdn.net/weixin_51928794/article/details/117256226） 在计算完第一个绿色的三角形之后，开始计算第二个蓝色的三角形，这时又遍历到了上面异常的黑边处，也就是有一点点绿色的黑边，需要比较深度缓存来决定蓝色三角形是否要在该像素绘制。在每个像素采样计算时，三角形的覆盖是按照4x4采样计算的，但是深度值是按照像素级别1x1计算和存储来的， 之前该像素位置只存储了绿色三角形的深度值，蓝色三角形在绿色之后，所以深度比较失败，从而导致了该处不会再更新像素值。 解决方法：Games101｜作业2 + 光栅化 + SSAA vs MSAA + 黑边问题 - 知乎 (zhihu.com) 为了解决这个问题，我们可以在光栅化的时候，确保边界上的每个三角形的每个小像素都被考虑到，即在过完每个 边界上的像素后，我们确保记录下它的frame buffer，并清除它的depth buffer。这样上图的蓝色小像素就不会因为depth_buf的原因，而没被记录。如何确定哪个像素在边界上？通过在三角形的小像素的个数。 翻译一下这个方案，就是通过比较上下重叠的两个物体，谁在边界处对像素的samples覆盖得更多，取覆盖的更多的那个颜色（且不稀释？） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//Screen space rasterizationvoid rst::rasterizer::rasterize_triangle(const Triangle&amp; t) &#123; auto v = t.toVector4(); float min_x = width; float max_x = 0; float min_y = height; float max_y = 0; // find out the bounding box of current triangle for(int i = 0; i &lt; 3; i++) &#123; min_x = std::min(v[i].x(), min_x); max_x = std::max(v[i].x(), max_x); min_y = std::min(v[i].y(), min_y); max_y = std::max(v[i].y(), max_y); &#125; // iterate through the pixel for(int y = min_y; y &lt; max_y; y++) &#123; for(int x = min_x; x &lt; max_x; x++) &#123; int index = get_index(x, y); float count = 0.0; float max_count = ssaa_w*ssaa_h; for(float j = start_point; j &lt; 1.0; j+=pixel_size_sm) &#123; for(float i = start_point; i &lt; 1.0; i+=pixel_size_sm) &#123; if(insideTriangle(x+i, y+j, t.v)) &#123; count += 1.0; &#125; &#125; &#125; // find if the current pixel is inside the triangle if(insideTriangle(x+0.5, y+0.5, t.v)) &#123; // if so, use the following code to get the interpolated z value. auto[alpha, beta, gamma] = computeBarycentric2D(x+0.5, y+0.5, t.v); float w_reciprocal = 1.0/(alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w()); float z_interpolated = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w(); z_interpolated *= w_reciprocal; // set the current pixel (use the set_pixel function) // to the color of the triangle (use getColor function) // if it should be painted. if(z_interpolated &lt; depth_buf[index]) &#123; Eigen::Vector3f p; p &lt;&lt; x, y, z_interpolated; Eigen::Vector3f color = t.getColor()*(count/max_count)+((max_count-count)/max_count)*frame_buf[index]; set_pixel(p, color); depth_buf[index] = z_interpolated; &#125; &#125; if(count &lt; max_count) &#123; depth_buf[index] = std::numeric_limits&lt;float&gt;::infinity(); &#125; &#125; &#125;&#125; Hw032022.04.21完成了Hw3，包括基于双线性插值的纹理采样。 首先是基于中心坐标的插值（rasterize_triangle方法中）: normal：用于phong shading，顶点的normal记录在obj中。 color：phong shading中的kd，triangle初始化时定义，目前是hardcode的。 texure_coords：通过插值找到当前像素在纹理贴图上的uv坐标，uv坐标取值范围为[0, 1]，将查找到的color作为kd进行shading，顶点的texure_coords记录在obj中。 shading_coods：通过model和view变换之后的position用于shading的计算，因为投影之后失去了3d的几何性质，向量I，向量V都需要这个坐标才可以计算出来。 phong_shader中，使用了blinn-phong着色模型，分为ambient，diffuse，specular三个分量，三者叠加。如果环境中有几个光源，那么最终的结果是几个光源分别作用在物体上的三个分量之和的叠加。 1234567891011121314151617 Eigen::Vector3f result_color = &#123;0, 0, 0&#125;;for (auto&amp; light : lights) &#123; // TODO: For each light source in the code, calculate what the *ambient*, *diffuse*, and *specular* // components are. Then, accumulate that result on the *result_color* object. float r2 = (light.position - point).dot(light.position - point); Eigen::Vector3f l = (light.position - point).normalized(); // Eigen::Vector3f n = normal - point; Eigen::Vector3f v = (eye_pos - point).normalized(); // 要用矩阵的对应元素相乘cwiseProduct才可以，因为rgb三个方向的强度、ka\\kb\\ks可能都不一样，分开计算。 // 向量只有点乘和叉乘，点乘得到数，叉乘得到向量。 // 点乘可以用a.dot(b), 也可以a.transpose() * b (a,b是行数相同的vector) Eigen::Vector3f ambient = ka.cwiseProduct(amb_light_intensity); Eigen::Vector3f diffuse = kd.cwiseProduct(light.intensity / r2) * std::max(0.0f, normal.dot(l)); Eigen::Vector3f specular = ks.cwiseProduct(light.intensity / r2) * pow(std::max(0.0f, normal.dot((l + v).normalized())), p); result_color += ambient + diffuse + specular; &#125; bump和displacement贴图都是需要使用TBN和微分计算出来的位移切线方向来计算新的normal向量，在这个作业中，bump_shader直接输出的时normal作为颜色；displacement_shader在此基础上，还要重新计算position_view（因为顶点是真的发生了移动），然后重新应用phong_shading来进行着色。 在bump内我加了blinn-phong模型与displacement的效果进行对比。 1234567891011121314151617181920212223242526272829303132float kh = 0.2, kn = 0.1;// TODO: Implement displacement mapping here// Let n = normal = (x, y, z)Eigen::Vector3f n = normal;// Vector t = (x*y/sqrt(x*x+z*z),sqrt(x*x+z*z),z*y/sqrt(x*x+z*z))float x = n.x();float y = n.y();float z = n.z();Eigen::Vector3f t&#123;x*y/sqrt(x*x+z*z), sqrt(x*x+z*z), z*y/sqrt(x*x+z*z)&#125;;// Vector b = n cross product tEigen::Vector3f b = n.cross(t);// Matrix TBN = [t b n]Eigen::Matrix3f TBN;TBN &lt;&lt; t, b, n;// ??????????????????????????不懂 但好像又有点懂// dU = kh * kn * (h(u+1/w,v)-h(u,v))float w = payload.texture-&gt;width;float h = payload.texture-&gt;height;float u = payload.tex_coords.x();float v = payload.tex_coords.y();// 在这里norm一下取模长，近似为高度？float dU = kh * kn * (payload.texture-&gt;getColor(u+1.0f/w,v).norm() - payload.texture-&gt;getColor(u,v).norm());// dV = kh * kn * (h(u,v+1/h)-h(u,v))float dV = kh * kn * (payload.texture-&gt;getColor(u,v+1.0f/h).norm() - payload.texture-&gt;getColor(u,v).norm());// Vector ln = (-dU, -dV, 1)Eigen::Vector3f ln&#123;-dU, -dV, 1.0f&#125;;// Position p = p + kn * n * h(u,v)point = point + kn * n * payload.texture-&gt;getColor(u,v).norm();// Normal n = normalize(TBN * ln)n = (TBN * ln).normalized(); 如下图所示： 最后是双线性插值（关键点在注释中）： 12345678910111213141516171819202122232425262728293031323334// 双线性插值进行纹理采样Eigen::Vector3f getColorBilinear(float u, float v)&#123; float u_img = u * static_cast&lt;float&gt;(width); float v_img = (1 - v) * static_cast&lt;float&gt;(height); float u_img_round = round(u_img); float v_img_round = round(v_img); std::vector&lt;Eigen::Vector2f&gt; neighbours &#123; // opencv的坐标x,y是反的.......... // https://blog.csdn.net/sc944201630/article/details/82222909 // ↙ &#123;u_img_round - 0.5f, v_img_round + 0.5f&#125;, // &#123;u_img_round - 1.0f, v_img_round + 1.0f&#125;, // ↘ &#123;u_img_round + 0.5f, v_img_round + 0.5f&#125;, // &#123;u_img_round , v_img_round + 1.0f&#125;, // ↖ &#123;u_img_round - 0.5f, v_img_round - 0.5f&#125;, // &#123;u_img_round - 1.0f, v_img_round&#125;, // ↗ &#123;u_img_round + 0.5f, v_img_round - 0.5f&#125; // &#123;u_img_round, v_img_round&#125; &#125;; float s = u_img - neighbours[2].x(); float t = v_img - neighbours[2].y(); // float s = u_img - neighbours[2].x() - 0.5f; // float t = v_img - neighbours[2].y() + 0.5f; // 对于s/t的计算，不论是以整数为单位还是0.5(pixel中心)为单位，结果都是一样的，无非整体-0.5或+0.5 // 唯一不同的就是getColor的取值罢了，实验下来，以0.5为单位的结果和未插值的结果是一样的。 Eigen::Vector3f down_lerp = lerp(s, getColor(neighbours[2]), getColor(neighbours[3])); Eigen::Vector3f up_lerp = lerp(s, getColor(neighbours[0]), getColor(neighbours[1])); return lerp(t, down_lerp, up_lerp);&#125; 还要注意的是，opencv的坐标系是从左上方开始的，不是左下方。 悬而未决：以pixel中心的坐标作为opencv的输入才可以得到与未插值的时候相同的结果（是说坐标的偏移等等），为什么？可能是因为opencv本身要求就是输入pixel中心的坐标来得到相应的color吧。 结果如下图，分别是512 * 512(small)以及256 * 256(tiny)的纹理贴图未应用&#x2F;应用了双线性插值： small-未应用 small-已应用 tiny-未应用 tiny-已应用 可以看到，效果还是很明显的，应用了双线性插值之后，马赛克的现象好了很多。 2022&#x2F;04&#x2F;22Segment Fault 1: Texture.hpp中，根据uv getColor()的时候，uv要先格式化为[0, 1]之间； 1234if(u &gt; 1) u = 1;if(v &gt; 1) v = 1;if(u &lt; 0) u = 0;if(v &lt; 0) v = 0; 2: rock.obj，如果相机离物体太近，也会段错误。所以把eye_pos的z坐标改大。因为物体在世界坐标系原点，相机指向-z方向，相当于朝着z正方向平移（view变换里的矩阵值是-z）。 其他obj的渲染结果如下： 这是在main改了eye_pos，shader里面的eye_pos同步修改的结果。 这是在main改了eye_pos，shader里面的eye_pos未同步修改的结果。 可以看到(0, 0, 2)和(0, 0, 10)的eye_pos在phong shader里面的差别并不大。 然后，为了验证当obj位于相机背后时，成像会是倒立的（小孔成像原理），将eye_pos改为(0, 0, -2)，效果如下，可以看到，确实成像是倒立的，并且是面朝成像平面，而非背部。 然后是rock.obj： cube.obj： Crate1.obj：这个模型本身顶点有问题，详见-&gt;作业3换模型—crate出大问题 – 计算机图形学与混合现实在线平台 (games-cn.org)。 Hw042022&#x2F;05&#x2F;21使用优先队列实现了De Casteljau算法，如下图所示。 暂时没有实现反走样。 总结一下： iterator如果是const对象的迭代器的话，会比较麻烦，用auto比较方便；访问值要用*it，迭代的时候直接it++即可； 思路是使用优先队列来对曲线上的点进行求取；需要注意的是queue的pop()不会返回值； opencv库，at()函数用于绘制像素的颜色，[0] [1] [2] 分别是b&#x2F;g&#x2F;r通道；后面的值为通道的颜色的浓淡，255最浓。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647cv::Point2f recursive_bezier(const std::vector&lt;cv::Point2f&gt; &amp;control_points, float t) &#123; // TODO: Implement de Casteljau&#x27;s algorithm std::queue&lt;cv::Point2f&gt; current_points; for(auto it = control_points.begin(); it != control_points.end(); it++) &#123; current_points.push(*it); &#125; int total_num = current_points.size(); int count = total_num; while(total_num != 1) &#123; if(count &gt; 1) &#123; count--; cv::Point2f begin_point = current_points.front(); current_points.pop(); cv::Point2f end_point = current_points.front(); current_points.push(begin_point + t * (end_point - begin_point)); &#125; else &#123; current_points.pop(); total_num = current_points.size(); count = total_num; &#125; &#125; return current_points.front();&#125;void bezier(const std::vector&lt;cv::Point2f&gt; &amp;control_points, cv::Mat &amp;window) &#123; // TODO: Iterate through all t = 0 to t = 1 with small steps, and call de Casteljau&#x27;s // recursive Bezier algorithm. for(float t = 0.0; t &lt;= 1.0; t += 0.001) &#123; // at()函数 // 对于单通道图像&quot;picture1&quot;，picture1.at&lt;uchar&gt;(i,j)就表示在第i行第j列的像素值。 // 对于多通道图像如RGB图像&quot;picture2&quot;，可以用picture2.at&lt;Vec3b&gt;(i,j)[c]来表示某个通道中在(i,j)位置的像素值。 // 1）上面的uchar、Vec3b表示图像元素的类型。 // 2）(i,j)当然就是指像素点的位置，表示第i行第j列。 // 3）[c]表示的是通道，对于RGB图像而言，c取0就是B分量；c取1就是G分量；c取2就是R分量（要注意在OpenCV中是按BGR的顺序表示的）。 auto point = recursive_bezier(control_points, t); window.at&lt;cv::Vec3b&gt;(point.y, point.x)[1] = 255; &#125;&#125; 2022&#x2F;06&#x2F;07实现了反走样： 具体实现如下： 简单来说就是分别查看着色点到它周围9个像素的距离，从而生成颜色的浓度ratio比例，乘上255即可。 1234567891011121314// 参考: https://blog.csdn.net/ycrsw/article/details/124117190for (int i = -1; i &lt;= 1; i++)&#123; for (int j = -1; j &lt;= 1; j++) &#123; // 不处理越界像素 if (point.x + i &gt; 700 || point.x + i &lt; 0 || point.y + j &gt; 700 || point.y + j &lt; 0) continue; // 计算ratio ratio = 1 - sqrt(2)*sqrt(pow(point.y - int(point.y + j) - 0.5, 2) + pow(point.x - int(point.x + i) - 0.5, 2)) / 3; // 计算像素颜色 window.at&lt;cv::Vec3b&gt;(point.y + j, point.x + i)[2] = std::fmax(window.at&lt;cv::Vec3b&gt;(point.y + j, point.x + i)[2], 255 * ratio); &#125;&#125; Hw052022&#x2F;05&#x2F;29 Renderer() 在这里需要注意Raster Space到NDC Space的变换（归一化到[0, 1]）； 以及NDC Space到Screen Space的变换（缩放到[-1, 1]）。 123456789101112131415161718192021222324for (int j = 0; j &lt; scene.height; ++j)&#123; for (int i = 0; i &lt; scene.width; ++i) &#123; // generate primary ray direction float x; float y; // TODO: Find the x and y positions of the current pixel to get the direction // vector that passes through it. // Also, don&#x27;t forget to multiply both of them with the variable *scale*, and // x (horizontal) variable with the *imageAspectRatio* // https://blog.csdn.net/dong89801033/article/details/114834898?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162216944616780357298394%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=162216944616780357298394&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-114834898.pc_search_result_cache&amp;utm_term=games101%E4%BD%9C%E4%B8%9A5&amp;spm=1018.2226.3001.4187 x = (2 * (i + 0.5) / scene.width - 1) * scale * imageAspectRatio; y = (1 - 2 * (j + 0.5) / scene.height) * scale; Vector3f dir = Vector3f(x, y, -1); // Don&#x27;t forget to normalize this direction! // norm()是返回二范数 // normalize()是直接把自身的各元素除以二范数 // normalized()是返回一个标准化的向量 dir = normalize(dir); framebuffer[m++] = castRay(eye_pos, dir, scene, 0); &#125; UpdateProgress(j / (float)scene.height);&#125; 其中，Scale是用于缩放视场的变量；imageAspectRatio是宽高比，因为归一化到[-1, 1]之后可能会对图像造成拉伸，所以需要沿着x轴进行缩放。 From: x’ &#x2F; y &#x3D; width &#x2F; height &#x3D; imageAspectRatio; And x &#x3D; y; Thus: x’ &#x3D; imageAspectRatio * x; CastRay() ①菲涅尔方程 ②Phong Illuminating Model ③Lambert Cosine Law rayTriangleIntersect() Moller_Trumbore：快速求出光线(origin_point &amp; direction)和三角形(v0, v1, v2)的交点。 结果： Hw062022&#x2F;05&#x2F;30BVH加速求交：完成了BVH加速与物体求交的过程。 其中比较关键的是建树和求交这两个过程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// 建树BVHBuildNode* BVHAccel::recursiveBuild(std::vector&lt;Object*&gt; objects)&#123; // 使用new动态申请在heap的空间，需要手动delete，所以可以作为返回值 BVHBuildNode* node = new BVHBuildNode(); // Compute bounds of all primitives in BVH node Bounds3 bounds; for (int i = 0; i &lt; objects.size(); ++i) bounds = Union(bounds, objects[i]-&gt;getBounds()); if (objects.size() == 1) &#123; // Create leaf _BVHBuildNode_ node-&gt;bounds = objects[0]-&gt;getBounds(); node-&gt;object = objects[0]; node-&gt;left = nullptr; node-&gt;right = nullptr; return node; &#125; else if (objects.size() == 2) &#123; // 左值: std::vector&lt;Object*&gt; new_vec = &#123;objects[0]&#125;; // std::vector&#123;objects[0]&#125; 创建了一个右值 // 之所以要这么写是因为这只是一个临时变量，之后用不到 // 翻译一下传值的过程： // 1. 创建匿名变量 std::vector&#123;objects[0]&#125; // 2. 函数内：创建局部变量std::vector&lt;Object*&gt; objects = 匿名变量 // 3. 复制Object* 类型数据objects[0]到objects内存所在区域（因为只是给指针赋值所以不会发生对象的拷贝构造） node-&gt;left = recursiveBuild(std::vector&#123;objects[0]&#125;); node-&gt;right = recursiveBuild(std::vector&#123;objects[1]&#125;); node-&gt;bounds = Union(node-&gt;left-&gt;bounds, node-&gt;right-&gt;bounds); return node; &#125; else &#123; Bounds3 centroidBounds; for (int i = 0; i &lt; objects.size(); ++i) centroidBounds = Union(centroidBounds, objects[i]-&gt;getBounds().Centroid()); int dim = centroidBounds.maxExtent(); switch (dim) &#123; case 0: std::sort(objects.begin(), objects.end(), [](auto f1, auto f2) &#123; return f1-&gt;getBounds().Centroid().x &lt; f2-&gt;getBounds().Centroid().x; &#125;); break; case 1: std::sort(objects.begin(), objects.end(), [](auto f1, auto f2) &#123; return f1-&gt;getBounds().Centroid().y &lt; f2-&gt;getBounds().Centroid().y; &#125;); break; case 2: std::sort(objects.begin(), objects.end(), [](auto f1, auto f2) &#123; return f1-&gt;getBounds().Centroid().z &lt; f2-&gt;getBounds().Centroid().z; &#125;); break; &#125; auto beginning = objects.begin(); auto middling = objects.begin() + (objects.size() / 2); auto ending = objects.end(); auto leftshapes = std::vector&lt;Object*&gt;(beginning, middling); auto rightshapes = std::vector&lt;Object*&gt;(middling, ending); assert(objects.size() == (leftshapes.size() + rightshapes.size())); node-&gt;left = recursiveBuild(leftshapes); node-&gt;right = recursiveBuild(rightshapes); node-&gt;bounds = Union(node-&gt;left-&gt;bounds, node-&gt;right-&gt;bounds); &#125; return node;&#125;// 求交Intersection BVHAccel::getIntersection(BVHBuildNode* node, const Ray&amp; ray) const&#123; // TODO Traverse the BVH to find intersection Intersection isect; if (!node-&gt;bounds.IntersectP(ray, ray.direction_inv, std::array&#123;(int)ray.direction.x, (int)ray.direction.y, (int)ray.direction.z&#125;)) return isect; if (node-&gt;left == nullptr &amp;&amp; node-&gt;right == nullptr) return node-&gt;object-&gt;getIntersection(ray); Intersection isect_r = getIntersection(node-&gt;right, ray); Intersection isect_l = getIntersection(node-&gt;left, ray); if (!isect_r.happened &amp;&amp; !isect_l.happened) return isect; return isect_r.distance &lt; isect_l.distance ? isect_r : isect_l;&#125; 2022&#x2F;05&#x2F;31SAH加速求交： SAH加速的目标主要是在优化 C &#x3D; Ctrav + SA&#x2F;SN * NA * Cisect + SB&#x2F;SN * NB * Cisect 这个时间开销上。 又因为，针对同一个父节点，不同划分方式下的子节点Ctrav、SN、Cisect 都相同，所以可以被省略掉，得到一个相对的时间开销： C* &#x3D; SA * NA + SB * NB 于此同时，还可以通过将遍历的次数从N-1，缩小到确定值B来进行加速。 具体来说，原本一共有N个objects，如果是按照原本的划分方法，一共有N-1次种划分方法，需要循环N-1次；但如果是限制为均匀划分为B个桶，那么只用循环B次。这里设置B为min(10, objects.size())。 要注意迭代器的使用时的边界问题。 123456789101112131415161718192021222324252627282930313233343536373839404142// 这里是均匀划分B个桶,这样的话,只用循环B次.// 优化一下,objects.size()小于10的,那么B = objects.size().int B = std::min(10, (int)objects.size());int best_index = 1;double best_time_cost = std::numeric_limits&lt;double&gt;::max();for (int i = 1; i &lt; B; ++i)&#123; int separate_num = objects.size() * i / B; Bounds3 bounds_1, bounds_2; for (int j = 0; j &lt; objects.size(); ++j) &#123; if (j &lt; separate_num) bounds_1 = Union(bounds_1, objects[j]-&gt;getBounds()); else bounds_2 = Union(bounds_2, objects[j]-&gt;getBounds()); &#125; double S1 = bounds_1.SurfaceArea(); double S2 = bounds_2.SurfaceArea(); double time_cost = S1 * separate_num + S2 * (objects.size() - separate_num); if (time_cost &lt; best_time_cost) &#123; best_time_cost = time_cost; best_index = i; &#125;&#125;std::cout &lt;&lt; best_index &lt;&lt; std::endl;// beginning指向vector第一个元素// ending指向vector最后一个元素的后面那个空位,而不是最后一位元素auto beginning = objects.begin();auto middling = objects.begin() + objects.size() * best_index / B;auto ending = objects.end();// 注意,是取不到middling这个下标的,只取得到前一位(左闭右开)// 所以迭代器begin()+i,下面这种构造方式内就只有i个元素auto leftshapes = std::vector&lt;Object*&gt;(beginning, middling);auto rightshapes = std::vector&lt;Object*&gt;(middling, ending);assert(objects.size() == (leftshapes.size() + rightshapes.size()));node-&gt;left = recursiveBuild(leftshapes);node-&gt;right = recursiveBuild(rightshapes);node-&gt;bounds = Union(node-&gt;left-&gt;bounds, node-&gt;right-&gt;bounds); 在求交的时候，依旧存在一个加速的方法。 1234567891011121314151617181920212223242526272829303132float t_Min_x = (pMin.x - ray.origin.x)*invDir[0];float t_Min_y = (pMin.y - ray.origin.y)*invDir[1];float t_Min_z = (pMin.z - ray.origin.z)*invDir[2];float t_Max_x = (pMax.x - ray.origin.x)*invDir[0];float t_Max_y = (pMax.y - ray.origin.y)*invDir[1];float t_Max_z = (pMax.z - ray.origin.z)*invDir[2];//如果发现射线的方向是反的，调换t_min和t_max的位置。if(dirIsNeg[0])&#123; float t = t_Min_x; t_Min_x = t_Max_x; t_Max_x = t;&#125;if(dirIsNeg[1])&#123; float t = t_Min_y; t_Min_y = t_Max_y; t_Max_y = t;&#125;if(dirIsNeg[2])&#123; float t = t_Min_z; t_Min_z = t_Max_z; t_Max_z = t;&#125; float t_enter = std::max(t_Min_x, std::max(t_Min_y, t_Min_z));float t_exit = std::min(t_Max_x, std::min(t_Max_y, t_Max_z));if(t_enter &lt; t_exit &amp;&amp; t_exit &gt;= 0) return true;return false; dirIsNeg的定义： 12345678910111213141516171819202122Intersection BVHAccel::getIntersection(BVHBuildNode* node, const Ray&amp; ray) const&#123; // TODO Traverse the BVH to find intersection Intersection isect; std::array&lt;int, 3&gt; dirIsNeg; dirIsNeg[0] = ray.direction.x &lt; 0; dirIsNeg[1] = ray.direction.y &lt; 0; dirIsNeg[2] = ray.direction.z &lt; 0; // Note：IntersectP()参数最后是一个引用，这里这样写，是直接传了右值std::array&#123;(int)ray.direction.x, (int)ray.direction.y, (int)ray.direction.z&#125; // 和引用绑定。这样是不行的，因为右值的内存在语句结束后就会被释放，就算和引用绑定也没有用了。 // 所以，函数的参数是指针或者引用的时候，不能传右值，只能传左值，因为不会开辟新的内存。&lt;传地址&gt;； // 同理，函数的参数传递如果是&lt;传值&gt;，那就可以传右值，因为是开辟了一个新的内存copy。 // if (!node-&gt;bounds.IntersectP(ray, ray.direction_inv, std::array&#123;(int)ray.direction.x, (int)ray.direction.y, (int)ray.direction.z&#125;)) if (!node-&gt;bounds.IntersectP(ray, ray.direction_inv, dirIsNeg)) return isect; if (node-&gt;left == nullptr &amp;&amp; node-&gt;right == nullptr) return node-&gt;object-&gt;getIntersection(ray); Intersection isect_r = getIntersection(node-&gt;right, ray); Intersection isect_l = getIntersection(node-&gt;left, ray); if (!isect_r.happened &amp;&amp; !isect_l.happened) return isect; return isect_r.distance &lt; isect_l.distance ? isect_r : isect_l;&#125; 为什么可以用dir的正负来进行求交的加速呢？ 这里是由于，p &#x3D; t * dir + oringin，所以 t &#x3D; (p - origin) &#x2F; dir； pmax点对应计算出的t_max 与 pmin点对应计算出的t_min的大小关系可以相减得到： t_max - t_min &#x3D; (pmax - pmin) &#x2F; dir ① 又因为pmax的三维分量一定是 &gt; pmin的，所以式①的正负由dir的正负决定。且p_max一定 &gt; p_min，因此t_min ≠ t_max，因此t_min和t_max只有两种大小关系。 又因为x&#x2F;y&#x2F;z轴每个分量的t_min和t_max需要用于计算t_enter和t_exit，我们希望t_min代表进入对面，t_max代表离开对面，这就意味着t_min &lt; t_max一定需要成立。 因此，若dir &gt; 0，那么计算出来的t_min &lt; t_max，满足我们的期望；反之，t_min &gt; t_max，与我们的期望不符合，所以需要将这两个值进行互换。 结果如下：这里是没有加dir&lt;0判断加速的BVH耗时： 这里是使用了SAH，dir&lt;0，以及划分桶进行加速的耗时： 渲染结果如下图所示： BVH和加速之后的结果一样，这里只放一张。 Hw072022&#x2F;06&#x2F;08完成了Path Tracing、多线程、Microfacet。 课程讲解主要是遵循diffuse的情况进行的。因此，代码中的material中关于BRDF和光线的采样，以及pdf都是有关联的。 diffuse的采样是在整个半球空间中进行的（因为漫反射方向是四面八方，且光线可逆，因此入射光线的采样方向也是四面八方），且是均匀采样，因此pdf &#x3D; 1&#x2F;2Π； 值得注意的是，因为方形的obj是面，可能会存在n和wo的夹角cos值&lt;0（也就是不在正半球方向上，夹角大于2&#x2F;Π）。其次，如果在triangle求交上，没有在原代码的基础上判断t &lt; 0的情况，那么渲染结果就会缺一角。 同时，在方向角上的积分应用diffuse的性质，可以得到BRDF的值等于abedo&#x2F;Π；abedo∈[0, 1]。 因为这个渲染是在CPU上，所以可以用多线程来进行并行渲染，有两种方法，一种是使用thread库，另一种是使用omp库。注意不要忘记virtual box的cpu核心数需要修改。 注意两者写法上的不同。 在这里使用了匿名函数renderRows，具体来说，就是每个线程分配不同行数的像素进行渲染，因为需要写同一个变量，所以需要加互斥锁进行保护。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102// 采样数/pixelint spp = 1024;// MSAA采样形状一定是方形int size_msaa = sqrt(spp);float spp_step = 1.f / (float)size_msaa;std::cout &lt;&lt; &quot;SPP: &quot; &lt;&lt; spp &lt;&lt; &quot;\\n&quot;;// for (uint32_t j = 0; j &lt; scene.height; ++j) &#123;// for (uint32_t i = 0; i &lt; scene.width; ++i) &#123;// // generate primary ray direction// float x = (2 * (i + 0.5) / (float)scene.width - 1) *// imageAspectRatio * scale;// float y = (1 - 2 * (j + 0.5) / (float)scene.height) * scale;// Vector3f dir = normalize(Vector3f(-x, y, 1));// for (int k = 0; k &lt; spp; k++)&#123;// framebuffer[m] += scene.castRay(Ray(eye_pos, dir), 0) / spp; // &#125;// m++;// &#125;// UpdateProgress(j / (float)scene.height);// &#125;int num_threads = 16;int thread_height = scene.height / num_threads;// ====================thread====================// std::thread th[num_threads];// auto renderRows = [&amp;](uint32_t start_height, uint32_t end_height)// &#123;// for (uint32_t j = start_height; j &lt; end_height; ++j)// &#123;// for (uint32_t i = 0; i &lt; scene.width; ++i)// &#123;// // generate primary ray direction// // float x = (2 * (i + 0.5) / (float)scene.width - 1) *// // imageAspectRatio * scale;// // float y = (1 - 2 * (j + 0.5) / (float)scene.height) * scale;// // Vector3f dir = normalize(Vector3f(-x, y, 1));// // for (int k = 0; k &lt; spp; k++)&#123;// // framebuffer[(int)(j * scene.width + i)] += scene.castRay(Ray(eye_pos, dir), 0) / spp; // // &#125;// // MSAA 抗锯齿// for (int k = 0; k &lt; spp; k++)&#123;// float x = (2.0f * (i + spp_step / 2.0f + k % size_msaa) / (float)scene.width - 1) *// imageAspectRatio * scale;// float y = (1 - 2.0f * (j + spp_step / 2.0f + k / size_msaa) / (float)scene.height) * scale;// Vector3f dir = normalize(Vector3f(-x, y, 1));// framebuffer[(int)(j * scene.width + i)] += scene.castRay(Ray(eye_pos, dir), 0) / spp; // &#125;// &#125;// mtx.lock();// progress++;// UpdateProgress(progress / (float)scene.height);// mtx.unlock();// &#125;// &#125;;// for (int t = 0; t &lt; num_threads; ++t)// &#123;// th[t] = std::thread(renderRows, t * thread_height, (t + 1) * thread_height);// &#125;// for (int t = 0; t &lt; num_threads; ++t)// &#123;// th[t].join();// &#125;// ====================OpenMP====================auto renderRows = [&amp;](uint32_t start_height, uint32_t end_height)&#123; for (uint32_t j = start_height; j &lt; end_height; ++j) &#123; for (uint32_t i = 0; i &lt; scene.width; ++i) &#123; // generate primary ray direction // float x = (2 * (i + 0.5) / (float)scene.width - 1) * // imageAspectRatio * scale; // float y = (1 - 2 * (j + 0.5) / (float)scene.height) * scale; // Vector3f dir = normalize(Vector3f(-x, y, 1)); // for (int k = 0; k &lt; spp; k++)&#123; // framebuffer[(int)(j * scene.width + i)] += scene.castRay(Ray(eye_pos, dir), 0) / spp; // &#125; // MSAA 抗锯齿 for (int k = 0; k &lt; spp; k++)&#123; float x = (2.0f * (i + spp_step / 2.0f + spp_step * (k % size_msaa)) / (float)scene.width - 1) * imageAspectRatio * scale; float y = (1 - 2.0f * (j + spp_step / 2.0f + spp_step * (k / size_msaa)) / (float)scene.height) * scale; Vector3f dir = normalize(Vector3f(-x, y, 1)); framebuffer[(int)(j * scene.width + i)] += scene.castRay(Ray(eye_pos, dir), 0) / spp; &#125; &#125; omp_set_lock(&amp;lock1); progress++; UpdateProgress(progress / (float)scene.height); omp_unset_lock(&amp;lock1); &#125;&#125;;#pragma omp parallel forfor (int t = 0; t &lt; num_threads; ++t) renderRows(t * thread_height, (t + 1) * thread_height);UpdateProgress(1.f); 除此之外，需要将CmakeList.txt中加上对应的部分。 12345# &lt;OpenMP&gt;set(CMAKE_CXX_FLAGS &quot;$&#123;CAMKE_CXX_FLAGS&#125; -O3 -fopenmp&quot;)# &lt;thread&gt;target_link_libraries(RayTracing pthread) 同时，需要在框架提供的随机数生成函数中，将三个局部变量设置为static类型，从而减少运行时间： 加之前 加之后 纯镜面反射存在过度曝光问题： 2022&#x2F;06&#x2F;11解决了specular材质的过度曝光问题。 首先，思考一下为什么会产生过度曝光？因为框架里面的path tracing是根据理想漫反射的情况分为了dir和indir两个部分。然而specular沿用这个框架，在对直接光照进行采样的时候只判断了n和wo的cos是否大于0，而没有判断是否满足镜面反射，所以只要采样的是光源，满足cos&gt;0的全部都加了起来，因此过曝了。 其次，再回顾一下，为什么需要拆分两个部分呢？因为引入了RR之后，如果只对立体角进行采样，那么有一种可能是循环停止时还采样不到光源，那么什么能量都没有，会造成巨大的浪费产生噪声，只能通过增大spp来减小噪声。 如果是理想diffuse上对立体角均匀采样的情况，造成的浪费只会是①dir中ray被物体挡住，以及②indir采到了光源或没碰到物体。 如果使用的是ggx(Microfacet)，对立体角均匀采样，浪费除了①和②，还会有③光线分布不符合D(h)。 之所以diffuse的浪费不包括③，是因为diffuse的D(h)本身就是均匀分布的，在半球上永远会被满足，这是性质，也是前提。 故，为了避免浪费③，才会引入重要性采样（猜测）。而diffuse的pdf和它在Microfacet中对应D(h)的形状是一样的，因此本身就满足了重要性采样的特点。 Specular的采样与pdf：(1)只向镜面方向采样，对应概率为1(不是pdf)，根据D(h)进行重要性采样 采样方向： 123456case SPECULAR:&#123; // 只采样 镜面反射方向 return reflect(wi, N); break;&#125; 设置对应的pdf为1，而不是∞，因为会被δ(wi-wr)抵消（后面会解释）。 123456case SPECULAR:&#123; if (dotProduct(wo, N) &gt; 0.0f) return 1.0f; else return 0.0f; break;&#125; ​ 1)改写BRDF(×): 因为框架拆分了dir和indir，BRDF内部需要判断sampleLight生成的方向是否与wi是关于N对称的，相对来说，判断两个量是否相等是非常困难的，往往需要用差值与一个很小的EPSILON对比，这样会造成误差，所以不能这样做。 ​ 2)改写Path Tracing(√): 将拆分了dir和indir的框架退化为不拆分的基本框架，依旧引入RR，但是因为引入了重要性采样，所以不会造成浪费。 123456789101112131415161718case SPECULAR:&#123; Vector3f L = &#123;0.0f, 0.0f, 0.0f&#125;; // 俄罗斯赌盘 是否继续采样 if (get_random_float() &gt; RussianRoulette) return L; // 对立体角采样 实际只有一个方向 Vector3f wi = p.m-&gt;sample(ray.direction, p.normal); float pdf = p.m-&gt;pdf(ray.direction, wi, p.normal); Ray ray_i_indir(p.coords, wi); Intersection q = intersect(ray_i_indir); if (q.happened) &#123; float div = pdf * RussianRoulette; L = castRay(ray_i_indir, ++depth) * p.m-&gt;eval(ray.direction, wi, p.normal) * dotProduct(wi, p.normal) / std::max(div , EPSILON); &#125; return L; break;&#125; (2)纯镜面反射的BRDF推导： 从上面我们可以看到，不论是重要性采样，还是均匀采样，都可以得到正确的结果，这也是为什么MC方法的分母不管取什么形状的pdf都一定无偏的原因，但是同时我们也知道，如果使用均匀采样(均匀采样的时候，BRDF项需要判断wi和wr是否相等，如果不相等，那么返回值为0，因为重要性采样的时候已经满足了相等的绝对条件，但是记住，判断相等是非常麻烦的一件事)，那么造成的浪费会很大，尤其是这种纯镜面反射的情况(必须要进行非常多的采样，才能采样到镜面方向)。 12345678910111213141516case SPECULAR:&#123; // Specular只考虑fresnel和delta函数(D(h)) // 这里 wi一定是和wo相对于n对称的 所以delta函数值一定是∞ float cosalpha = dotProduct(N, wo); if (cosalpha &gt; 0.0f) &#123; float kr; fresnel(wi, N, ior, kr); // 是根据全镜面反射的定义来的 // Lo = Fresnel * Li(i与r关于n对称) Vector3f specular = kr / std::max(cosalpha, EPSILON); return specular; &#125; else return Vector3f(0.0f); break;&#125; 这里原本fr&#x3D;δ(wi-wr)*F&#x2F;cosθi，但是由于wi&#x3D;&#x3D;wr，所以冲激函数值为∞，它理论上会被渲染方程里面的pdf所抵消，所以这里也和pdf一样设置为1即可。 渲染结果(spp&#x3D;10000)： MSAA 抗锯齿在没有实现MSAA的情况下，可以看到边缘会有走样的现象。 因此，参考MSAA的思想，将pixel平均分为spp个方格(super sampling)，向方格中心发射ray进行采样，然后取平均(blur)： 12345678// MSAA 抗锯齿for (int k = 0; k &lt; spp; k++)&#123; float x = (2.0f * (i + spp_step / 2.0f + spp_step * (k % size_msaa)) / (float)scene.width - 1) * imageAspectRatio * scale; float y = (1 - 2.0f * (j + spp_step / 2.0f + spp_step * (k / size_msaa)) / (float)scene.height) * scale; Vector3f dir = normalize(Vector3f(-x, y, 1)); framebuffer[(int)(j * scene.width + i)] += scene.castRay(Ray(eye_pos, dir), 0) / spp; &#125; 结果如下：可以看到边缘确实没有锯齿了。 GGX (不完整，没推导公式)根据OpenGL教程来编写GGX的Fresnel、D(h)和G(i, o, n)函数。 引入了roughness(影响D以及G值)以及metalness(影响F值)两个参数。 12345678910111213141516171819202122232425262728293031323334// https://learnopengl.com/PBR/Theory// https://blog.csdn.net/weixin_44518102/article/details/122698851?spm=1001.2101.3001.6650.9&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9.pc_relevant_default&amp;utm_relevant_index=12float DistributionGGX(const Vector3f&amp; N, const Vector3f&amp; H, const float&amp; a)&#123; float a2 = a * a; float NdotH = std::max(dotProduct(N, H), 0.0f); float NdotH2 = NdotH * NdotH; float nom = a2; float denom = (NdotH2 * (a2 - 1.0f) + 1.0f); denom = M_PI * denom * denom; // prevent divide by zero for roughness=0.0 and NdotH=1.0 return nom / std::max(denom, EPSILON);&#125;float GeometrySchlickGGX(const float&amp; NdotV, const float&amp; k)&#123; float nom = NdotV; float denom = NdotV * (1.0f - k) + k; return nom / denom;&#125;float GeometrySmith(const Vector3f&amp; N, const Vector3f&amp; V, const Vector3f&amp; L, const float&amp; k)&#123; float NdotV = std::max(dotProduct(N, V), 0.0f); float NdotL = std::max(dotProduct(N, L), 0.0f); float ggx1 = GeometrySchlickGGX(NdotV, k); float ggx2 = GeometrySchlickGGX(NdotL, k); return ggx1 * ggx2;&#125;Vector3f fresnelSchlick(float&amp; cosTheta, Vector3f&amp; F0)&#123; return F0 + (Vector3f(1.0f) - F0) * pow(1.0f - cosTheta, 5.0f);&#125; 对应的BRDF： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051case GGX:&#123; // 1. Ks 是 Specular 系数，其实就是 DFG 中的F，也就是菲涅尔项。 // 2. 框架中定义的 Kd 其实是 Color，在 Microfacet 中，Kd 的值应该是 1-Ks。 // 3. 最后得到的 fr = Kd * fr_diffuse + Ks * fr_specular。也就是要分别计算漫反射部分和高光部分， // 所以不要只顾计算 DFG 而忘了前面的漫反射部分。 // 4. 推荐看一下论坛上关于 Microfacet 讨论的这篇帖子，里面提到了很多典型问题，非常有启发性。 // 5. （2021年8月17日 更新）重点： 在GAME202 第10讲的最后，闫老师批驳了这种使用 Kd 做光照损失补偿的计算方法， // 称其没有任何物理原理可言。使用 Microfacet 方法会导致物体变暗，尤其是 Roughness值较大的物体会变得很暗， // 主要原因是因为在计算时没有计算多次光线弹射导致的能量损失。闫老师在 GAMES202 中介绍了 Kulla-Conty 方法 // 可以用于在实时渲染中进行能量补偿，可以参考。B站评论上有人说使用环境光进行补偿的方式是工业界经常使用的一种近似计算方法， // 不过个人感觉既然是在做学术界的作业，还是不要使用这在学术界上没有意义的计算方法。 // Normal Distribution Function // 粗糙度 if (dotProduct(wo, N) &gt; 0.0f) &#123; Vector3f V = -wi; Vector3f L = wo; Vector3f H = normalize(V + L); float D = DistributionGGX(N, H, roughness); // Geometry Function float G = GeometrySmith(N, V, L, k); Vector3f F0(0.04f); F0 = F0 * (1.0f - metalness) + Kd * metalness; float cosTheta = dotProduct(V, N); Vector3f F = fresnelSchlick(cosTheta, F0); Vector3f ks_ = F;//反射比率 Vector3f kd_ = Vector3f(1.0f) - ks_;//折射比率 // float F; // float etat = 1.85; // fresnel(wi, N, etat, F); // // 能量守恒 // float ks_ = F;//反射比率 // float kd_ = 1.0f - ks_;//折射比率 Vector3f diffuse = 1.0f / M_PI; Vector3f nominator = D * G * F; float denominator = 4.0f * dotProduct(N, V) * dotProduct(N, L); Vector3f specular = nominator / std::max(denominator, EPSILON); // 因为在 specular 项里已经考虑了反射部分的比例：F。所以反射部分不需要再乘以 ks_ // Ks为镜面反射项，Kd为漫反射项。 // return Ks * specular + kd_ * Kd * diffuse; return specular + kd_ * diffuse; &#125; else return Vector3f(0.0f); break;&#125; 看看一个ggx一个specular的效果，roughness&#x3D;0.1，metalness&#x3D;1.0： 重要性采样 (还没做)Gamma矫正 (还没做)","categories":[],"tags":[{"name":"图形学 GAMES101作业","slug":"图形学-GAMES101作业","permalink":"http://example.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6-GAMES101%E4%BD%9C%E4%B8%9A/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-11-01T13:12:14.442Z","updated":"2022-11-01T13:12:14.443Z","comments":true,"path":"2022/11/01/hello-world/","link":"","permalink":"http://example.com/2022/11/01/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"图形学 GAMES101作业","slug":"图形学-GAMES101作业","permalink":"http://example.com/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6-GAMES101%E4%BD%9C%E4%B8%9A/"}]}